import streamlit as st
import os
import sys

# --- å…³é”®ï¼šå°† src ç›®å½•åŠ å…¥ Python æœç´¢è·¯å¾„ ---
# è¿™æ · app.py æ‰èƒ½æ‰¾åˆ° src ä¸‹çš„ modules
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from rag_core02 import RAGSystem

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="RAG çŸ¥è¯†åº“åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide"
)

# --- æ ‡é¢˜ä¸ç®€ä»‹ ---
st.title("ğŸ¤– æœ¬åœ°åŒ– RAG ä¸ªäººçŸ¥è¯†åº“")
st.markdown("åŸºäº **DeepSeek-14B** + **ChromaDB** æ„å»ºçš„ç§æœ‰çŸ¥è¯†åŠ©æ‰‹")

# --- åˆå§‹åŒ– RAG ç³»ç»Ÿ (åˆ©ç”¨ Streamlit çš„ç¼“å­˜æœºåˆ¶) ---
# @st.cache_resource ç¡®ä¿ RAGSystem åªè¢«åˆå§‹åŒ–ä¸€æ¬¡ï¼Œ
# ä¸ä¼šå› ä¸ºç”¨æˆ·æ¯æ¬¡ç‚¹æŒ‰é’®éƒ½é‡æ–°åŠ è½½æ¨¡å‹ï¼ˆé‚£æ ·ä¼šå¾ˆæ…¢ï¼‰
@st.cache_resource
def load_rag_system():
    return RAGSystem()

try:
    with st.spinner("æ­£åœ¨å¯åŠ¨å¼•æ“ï¼ŒåŠ è½½çŸ¥è¯†åº“..."):
        rag = load_rag_system()
    st.success("âœ… ç³»ç»Ÿå°±ç»ªï¼")

except Exception as e:
    st.error(f"ç³»ç»Ÿå¯åŠ¨å¤±è´¥: {e}")
    st.stop()

# --- ä¾§è¾¹æ ï¼šåŠŸèƒ½åŒº ---
with st.sidebar:
    st.header("âš™ï¸ è®¾ç½®")
    st.info(
        "å½“å‰æ¨¡å‹: DeepSeek-R1-Distill-Qwen-14B\n"
        "è¿è¡Œæ¨¡å¼: Local (LM Studio)\n"
        "æ£€ç´¢ç­–ç•¥: Top-3 æ··åˆæ£€ç´¢"
    )

    # è¿™é‡Œæœªæ¥å¯ä»¥åŠ â€œä¸Šä¼ æ–‡ä»¶â€åŠŸèƒ½ï¼Œä¹Ÿå°±æ˜¯è°ƒç”¨ ingest.py
    if st.button("é‡æ–°æ„å»ºçŸ¥è¯†åº“(Ingest)"):
        st.warning("ç›®å‰è¯·åœ¨åå°è¿è¡Œ ingest.py æ‰‹åŠ¨æ›´æ–°æ•°æ®ã€‚")

# --- ä¸»èŠå¤©ç•Œé¢ ---

# åˆå§‹åŒ–èŠå¤©è®°å½•
if "messages" not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºå†å²æ¶ˆæ¯
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# æ¥æ”¶ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆå…³äºå·²ä¸Šä¼ çš„æ–‡æ¡£ï¼‰..."):
    # 1. æ˜¾ç¤ºç”¨æˆ·é—®é¢˜
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 2.è°ƒç”¨ RAG è·å–å›ç­”
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

    # æ˜¾ç¤ºâ€œæ­£åœ¨æ€è€ƒâ€çŠ¶æ€
    with st.spinner("DeepSeek æ­£åœ¨é˜…è¯»æ–‡æ¡£å¹¶æ€è€ƒ..."):
        # è°ƒç”¨åœ¨ rag_core.py é‡Œå†™çš„ query æ–¹æ³•
        response_obj = rag.query(prompt)

    if response_obj:
        # --- æµå¼æ¸²æŸ“æ ¸å¿ƒé€»è¾‘ ---
        # å¯¹åº” requests çš„æ‰‹åŠ¨è§£æé€»è¾‘ï¼ŒStreamlit ä¼šå®æ—¶åˆ·æ–°ç•Œé¢
        import json
        for line in response_obj.iter_lines():
            if line:
                decoded_line = line.decode("utf-8")
                if decoded_line.startswith("data:"):
                    json_str = decoded_line[6:]
                    if json_str.strip() == "[DONE]":
                        break
                    try:
                        json_data = json.loads(json_str)
                        content = json_data['choices'][0]['delta'].get('content', '')
                        if content:
                            full_response += content
                            # å®æ—¶æ›´æ–° UI
                            message_placeholder.markdown(full_response + "|")
                    except Exception as e:
                        print(e)

        message_placeholder.markdown(full_response)

        st.session_state.messages.append({"role": "assistant", "content": full_response})

    else:
        st.error("è¿æ¥è¶…æ—¶æˆ–æœªæ‰¾åˆ°ç­”æ¡ˆï¼Œè¯·æ£€æŸ¥ LM Studioã€‚")



